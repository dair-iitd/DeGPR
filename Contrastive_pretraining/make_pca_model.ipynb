{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "cuda = torch.cuda.is_available()\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib as mpl\n",
    "from dataset import SiameseCeliac\n",
    "import argparse\n",
    "from network import SupConResNet, LinearClassifier\n",
    "from utils import TwoCropTransform, AverageMeter\n",
    "from utils import adjust_learning_rate, warmup_learning_rate\n",
    "from utils import set_optimizer, save_model\n",
    "from losses import SupConLoss\n",
    "import torch.backends.cudnn as cudnn\n",
    "import sys\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_paths\n",
    "directory_path_root = '/home/aayush/Aayush/Projects/Celiac_Disease/Detection/Dataset/Celiac_cropped_patches_New_data/'\n",
    "train_directory_path = '/home/aayush/Aayush/Projects/Celiac_Disease/Detection/Dataset/Celiac_cropped_patches_New_data/train/'\n",
    "val_directory_path = '/home/aayush/Aayush/Projects/Celiac_Disease/Detection/Dataset/Celiac_cropped_patches_New_data/val/'\n",
    "test_directory_path = '/home/aayush/Aayush/Projects/Celiac_Disease/Detection/Dataset/Celiac_cropped_patches_New_data/test/'\n",
    "exp_dir = '/home/aayush/Aayush/Projects/Celiac_Disease/Detection/Code/Postreg/Contrastive_learning/save/SupCon/Celiac_Disease_bal_models/SupCon_Celiac_Disease_resnet18_lr_0.0001_decay_0.0001_bsz_8_temp_0.7_trial_0_kfold_0/'\n",
    "output_dir = '/home/aayush/Aayush/Projects/Celiac_Disease/Detection/Code/Postreg/Contrastive_learning/PCA/Resnet18_temp0d7/PCA_Contrastive_Balance/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "batch_size = 1\n",
    "syncBN = False\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model():\n",
    "    model = SupConResNet(name='resnet18')\n",
    "    criterion = SupConLoss(temperature=0.01)\n",
    "    \n",
    "    # load model\n",
    "    model_dir = exp_dir + 'ckpt_resnet18_epoch_250_temp_0.7.pth'\n",
    "    checkpoint = torch.load(model_dir)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    # enable synchronized Batch Normalization\n",
    "    if syncBN:\n",
    "        model = apex.parallel.convert_syncbn_model(model)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model.encoder = torch.nn.DataParallel(model.encoder)\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    return model, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_loader():\n",
    "    # load datasets\n",
    "    # Data loader for inference\n",
    "    means = (0.485, 0.456, 0.406)\n",
    "    stds = (0.229, 0.224, 0.225)\n",
    "    train_transform = transforms.Compose([transforms.Resize(image_size),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(means, stds)])\n",
    "    test_transform = transforms.Compose([\n",
    "                                    transforms.Resize(image_size),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(means, stds)])\n",
    "\n",
    "    train_data = datasets.ImageFolder(train_directory_path, transform=train_transform)\n",
    "    valid_data = datasets.ImageFolder(val_directory_path, transform=test_transform)\n",
    "    test_data = datasets.ImageFolder(test_directory_path, transform=test_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle= True)\n",
    "    val_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle = False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle = False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data loader\n",
    "train_loader, val_loader, test_loader = set_loader()\n",
    "model, criterion = set_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(data_loader, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        labels = None\n",
    "        embeddings = None\n",
    "        for batch_idx, data in tqdm(enumerate(data_loader)):\n",
    "            batch_imgs, batch_labels = data\n",
    "            batch_labels = batch_labels.numpy()\n",
    "            batch_imgs = Variable(batch_imgs.to(device))\n",
    "            bacth_E = model.encoder(batch_imgs)\n",
    "            bacth_E = bacth_E.data.cpu().numpy()\n",
    "            embeddings = np.concatenate((embeddings, bacth_E), axis=0) if embeddings is not None else bacth_E\n",
    "            labels = np.concatenate((labels, batch_labels), axis=0) if labels is not None else batch_labels\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train, labels_train = generate_embeddings(train_loader, model)\n",
    "embeddings_val, labels_val = generate_embeddings(val_loader, model)\n",
    "embeddings_test, labels_test = generate_embeddings(test_loader, model)\n",
    "\n",
    "print(embeddings_test.shape , labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_tSNE(embeddings, labels, split = 'train'):\n",
    "    tSNE_ns = 10000\n",
    "    num_samples = tSNE_ns if tSNE_ns < embeddings.shape[0] else embeddings.shape[0]\n",
    "    pca = PCA(n_components= 32, svd_solver='full', random_state=1001)\n",
    "    X_pca = pca.fit_transform(embeddings[0:num_samples, :])\n",
    "    X_embedded = TSNE(n_components=2).fit_transform(X_pca)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    x, y = X_embedded[:, 0], X_embedded[:, 1]\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
    "    sc = ax.scatter(x, y, c=labels[0:num_samples], cmap=mpl.colors.ListedColormap(colors))\n",
    "    plt.colorbar(sc)\n",
    "    if not os.path.exists(os.path.join(exp_dir, 'tSNE')):\n",
    "        os.makedirs(os.path.join(exp_dir, 'tSNE'))\n",
    "#     plt.savefig(os.path.join(exp_dir, 'tSNE', 'tSNE_edge_{}_'.format(split) + str(num_samples) + '.jpg'))\n",
    "    plt.show()\n",
    "\n",
    "vis_tSNE(embeddings_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pickle as pk\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.90)\n",
    "pca.fit(embeddings_train)\n",
    "print(pca.n_components_)\n",
    "pk.dump(pca, open(os.path.join(output_dir, \"pca_Celiac_contrastive_balance_new_data.pkl\"),\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
